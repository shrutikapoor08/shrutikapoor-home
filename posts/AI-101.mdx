---
title: Understand the AI Terms
description: 'These are the AI terms you must know RAG, MCP, Transformers, Generative AI, and ChatGPT, I’ll explain each concept in simple, clear language.'
date: July 17, 2025
featuredImage: https://i.ytimg.com/vi_webp/MfU27Ub-bs4/maxresdefault.webp
tags: Promotions
---

<iframe
  width="720"
  height="360"
  src="https://www.youtube.com/embed/MfU27Ub-bs4?si=-Nw2BWGTHeW4mzmN"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
  referrerpolicy="strict-origin-when-cross-origin"
  allowfullscreen
></iframe>

Are you finding it hard to understand AI terms? Do you sit in conversations and have no idea what's going on? This guide is for you. Let's break down today's artificial intelligence (AI) landscape, making it easy for anyone to grasp the core layers, terms, and technologies.

---

## 1. The Layers of the AI Ecosystem

**1.1 Hardware:**  
At the foundation, companies like Nvidia, AMD, Intel, and Huawei manufacture the physical processors that power AI computation. These chips are the "brain cells" of AI, enabling models to run, train, and perform tasks.

<img src="/images/ai-101/hardware-providers.png" style={{ margin: 'auto' }} />

**1.2 Cloud Providers:**  
Since hardware is expensive, cloud providers such as AWS, Google Cloud, Alibaba, and Microsoft Azure rent out these chips, offering computational resources to others. Think of them as factories providing the necessary tools for building products.

<img src="/images/ai-101/cloud-providers.png" style={{ margin: 'auto' }} />

**1.3 Model Builders:**  
On top of cloud providers, companies like OpenAI, Anthropic, Hugging Face, Meta, and Google use this computational power to create models—the "brains" of AI systems.

<img src="/images/ai-101/model-builders.png" style={{ margin: 'auto' }} />

**1.4 Applications:**  
These models power applications like ChatGPT, Claude, Midjourney, Canva AI, and more, which are the tools users interact with directly.

- Developers work on foundational models.
- Users interact with applications.

<img src="/images/ai-101/applications.png" style={{ margin: 'auto' }} />

---

## 2. What is AI?

### 2.1 AI

Artificial Intelligence (AI) is a field of computer science focused on making systems that can perform as well as human intelligence. The goal is to create systems that can think, recognize patterns, make predictions, and understand language like humans.

- The term "artificial intelligence" was coined in 1956.
- Alan Turing's 1950 paper introduced the "<a href='https://courses.cs.umbc.edu/471/papers/turing.pdf' target='_blank'>imitation game</a>", now called the Turing test, to see if machines can match human intelligence.

### 2.2 Machine Learning

Machine learning (ML) is a type of AI where machines learn from data.  
Instead of explicit instructions, machines find patterns and make predictions.

**Example:**  
If you provide the sequence 2, 4, 6, 8, 10, the model learns the pattern and predicts 12 as the next number.

**Real-world ML examples:**

- Netflix recommending movies
- Email clients learning to filter spam

### 2.3 Neural Networks

Neural networks are popular ML approaches that mimic brain cells.  
They consist of layers of "neurons" making yes/no decisions together.

**Example:**  
For image recognition (cat vs dog):

- Input layer: receives the image data
- Hidden layers: process features like fur, legs, facial features, whiskers
- Output layer: predicts, e.g., 85% cat, 15% dog

### 2.4 Deep Learning:

**Deep Learning** is a kind of machine learning that uses many layers of neural networks.

- The more hidden layers there are, the “deeper” the network.
- Deep learning is behind modern speech recognition, image recognition, and natural language processing systems.

---

## 3. AI Terms Simplified

### 3.1 Model

A **model** is the “brain” of an AI system. It’s a core unit trained on data to make predictions, generate content, or solve specific tasks. For example, GPT-4 is a model trained on massive amounts of text, capable of understanding and generating human language.

- Models are built by companies like OpenAI, Anthropic, Hugging Face, Meta, and Google.
- Think of a model as a trained dog that performs certain tasks.

### 3.2 Foundational Models

**Foundational models** are powerful models trained on enormous datasets—trillions of words, books, and texts. Their strength lies in adaptability: many applications can be built on top of them, either by using them as they are or by fine-tuning for specialized tasks (like medical or customer service applications).

- Examples: GPT-4 (OpenAI), Claude (Anthropic)
- Analogy: A foundational model is like a guide dog trained with numerous tricks, ready for many situations.

### 3.3 Large Language Models (LLM)

An **LLM** is a type of model trained specifically on vast text data, excelling at understanding and generating human language.

- Capabilities: predicting the next word, generating scripts, summarizing text, answering questions.
- Analogy: An LLM is like a dog that understands and responds to commands in multiple human languages.
- Example: ChatGPT is a popular LLM.

### 3.4 Generative AI

**Generative AI** refers to models that can create entirely new content—text, images, music—based on input prompts.

- Example: Given a prompt like “a woman eating cake while riding a camel on a mountaintop,” generative AI can produce a unique image that never existed before.
  <img
    src="/images/ai-101/ai-generated-woman-on-camel.png"
    style={{ margin: 'auto', width: '500px', padding: '20px 0px' }}
  />
- Generative models are not limited to analyzing data; they create new ideas, code, text, and media.

### 3.5 Transformer

A **transformer** is the architecture that powers modern language models.

- It enables models to understand not just individual words, but the context of entire sentences using “attention.”
- Example: In the sentence “The trophy didn’t fit in the suitcase because it was too big,” a transformer helps the AI know “it” refers to the trophy.
- First introduced in the paper “Attention Is All You Need” (2017).

### 3.6 GPT (Generative Pre-trained Transformer)

**GPT** stands for Generative Pre-trained Transformer, the technology behind models like ChatGPT.

- **Generative:** Can create new content from input.
- **Pre-trained:** Trained on large datasets beforehand.
- **Transformer:** Uses the transformer architecture for context and understanding.

### 3.7 Prompts

A **prompt** is the input or question you give to an AI model (especially an LLM).

- The quality of the prompt determines the quality of the output.
- Prompt engineering is the craft of writing clear, informative prompts to get the best results.

**Prompt Types:**

- **Zero-shot:** No examples, just the question.
- **Few-shot:** Some examples given to help the model understand context.
- **Chain of thought:** Encourages the model to reason step by step.

**CRISPR Method for Prompts:**

- Context, Role, Intent, Specificity, Parameters, Refinement

### 3.8 Token

A **token** is a chunk of text (word or part of a word) that the AI processes.

- More tokens in your prompt = higher computational cost.
- Example: “A cat and a dog” may be four tokens.

### 3.9 Hallucinations

**Hallucinations** happen when an AI model confidently produces incorrect or made-up answers.

- Always verify AI-generated information.
- Example: Asking an AI for the definition of MCP may yield a wrong answer.

---

## 4. Training Approaches

### 4.1 Supervised Learning

- **What it is:** The AI learns from examples that already have the right answers (labels).
- **How it works:** You show the model lots of data with correct answers, like pictures labeled “cat” or “dog.”
- **Result:** Next time the AI sees a new picture, it can guess if it’s a cat or a dog because it learned from the labeled examples.

### 4.2 Unsupervised Learning

- **What it is:** The AI is given data without any answers or labels.
- **How it works:** The model looks for patterns and groups in the data all by itself, without anyone telling it what’s right or wrong.
- **Result:** It can find clusters, trends, or common features in the data (like grouping customers by shopping habits).

### 4.3 Reinforcement Learning from Human Feedback (RLHF)

- **What it is:** The AI learns by getting feedback from humans.
- **How it works:** The model makes a prediction or does a task, and you give it a thumbs up or thumbs down. This feedback helps it improve over time.
- **Result:** The AI gets better at giving useful or correct answers because it learns from the feedback.

### 4.4 Fine-Tuning

- **What it is:** Making an already trained model smarter for a specific job.
- **How it works:** You take a big, general model (like GPT-4) and train it further on special data, like medical texts or legal documents.
- **Result:** The AI becomes an expert in a particular area without having to start learning from scratch.

---

## 5. AI Tools

### 5.1 RAG (Retrieval Augmented Generation)

- **What it is:** A method to help AI models answer questions more accurately by giving them access to extra information.
- **How it works:** Instead of only relying on what the model was trained on, you let the AI “retrieve” specific data (like from a database or document) when you ask a question.
- **Result:** The AI can use up-to-date or company-specific info to give better, more relevant answers.
- **Difference from Fine-Tuning:** RAG doesn’t train the model on new data—it just gives extra info to look up when responding.

### 5.2 AI Agents

- **What they are:** Software systems that can act autonomously or semi-autonomously to perform tasks using multiple tools or sources.
- **Examples:**
  - A code editor agent that reviews your work and suggests improvements.
  - A travel booking agent that creates an itinerary and recommends hotels.
- **How autonomous?** Most agents today help you by gathering information or making recommendations, but don’t fully automate everything. Their independence is expected to grow in the future.

### 5.3 MCP (Model Context Protocol)

- **What it is:** A standardized way for AI systems and smart devices to communicate with each other.
- **How it works:** Instead of building a custom link for each device or tool, MCP lets different systems talk using agreed-upon rules—making integration easier.
- **Why it matters:** MCP helps developers connect their tools to many AI systems without extra work, speeding up innovation and compatibility.

---

## Conclusion

The AI landscape consists of hardware, cloud providers, model builders, and applications.  
Understanding core terms—models, foundational models, LLMs, prompts, training approaches, RAG, agents, and MCP—empowers you to participate in AI discussions and make informed decisions.
